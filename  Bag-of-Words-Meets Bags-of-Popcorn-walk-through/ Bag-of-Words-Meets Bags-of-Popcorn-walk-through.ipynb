{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        TextBlob | vaderSentiment | nltk | re | bs4 | CountVectorizer | Word2Vec \n",
    "        \n",
    "        | TF-IDF | Pipeline | FeatrueUnion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis TextBlob and VaderSentiment\n",
    "            \n",
    "            TextBlob | vaderSentiment | np | pd | sklearn\n",
    "\n",
    "   [TextBlob](http://textblob.readthedocs.io/en/dev/quickstart.html#sentiment-analysis): build on nstk\n",
    "   \n",
    "   \n",
    "   [vaderSentiment](https://github.com/cjhutto/vaderSentiment): Sentiment Analysis\n",
    "   \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from textblob import TextBlob # build on nstk\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "analyzer = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "traindf = pd.DataFrame(columns=['id','sentiment','review'])\n",
    "idx = -1\n",
    "with open('data/labeledTrainData.tsv','r') as f:\n",
    "    for line in f.readlines():\n",
    "        if idx == -1:\n",
    "            pass\n",
    "        else:\n",
    "            traindf.loc[idx] = line.split(\"\\t\")\n",
    "        idx += 1\n",
    "# easier method:       \n",
    "# pd.read_csv(\"data/labeledTrainData.tsv\", header=0, \\\n",
    "#                    delimiter=\"\\t\", quoting=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "traindf.review = traindf.review.apply(lambda var: var.decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "traindf['textblod'] = traindf.review.apply(lambda var: TextBlob(var)) \n",
    "traindf['textblod-polarity'] = traindf.textblod.apply(lambda var: var.sentiment.polarity)\n",
    "traindf['textblod-subjectivity'] = traindf.textblod.apply(lambda var: var.sentiment.subjectivity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "traindf['vaderSentiment'] = traindf.review.apply(analyzer.polarity_scores);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "traindf['vaderSentiment-compound'] = traindf.vaderSentiment.apply(lambda var: var['compound'])\n",
    "traindf['vaderSentiment-neg'] = traindf.vaderSentiment.apply(lambda var: var['neg'])\n",
    "traindf['vaderSentiment-neu'] = traindf.vaderSentiment.apply(lambda var: var['neu'])\n",
    "traindf['vaderSentiment-pos'] = traindf.vaderSentiment.apply(lambda var: var['pos'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# quick classification based on sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python2.7/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/anaconda/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2864  834]\n",
      " [ 957 2845]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.75      0.77      0.76      3698\n",
      "        1.0       0.77      0.75      0.76      3802\n",
      "\n",
      "avg / total       0.76      0.76      0.76      7500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "\n",
    "X = np.array(traindf[['textblod-polarity','textblod-subjectivity', 'vaderSentiment-compound',\n",
    "            'vaderSentiment-neg','vaderSentiment-neu','vaderSentiment-pos']])\n",
    "y = np.array(traindf['sentiment'])\n",
    "X=X.astype('float32')\n",
    "y=y.astype('float32')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.30, random_state=325)\n",
    "\n",
    "rfc = SVC()\n",
    "rfc.fit(X_train,y_train)\n",
    "pred = rfc.predict(X_test)\n",
    "\n",
    "print confusion_matrix(y_test,pred)\n",
    "print '\\n'\n",
    "print classification_report(y_test,pred)\n",
    "# at most 77 using 2 layer neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Bag-of-words NB classifiers\n",
    "\n",
    "## Get Clean String\n",
    "\n",
    "        word2vectorizer | BeautifulSoup4 | re(regularexpression) | "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ### bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " the obvious message of drugs are bad m'kay.<br /><br />Visually impressive but of course this is al\n",
      " the obvious message of drugs are bad m'kay.Visually impressive but of course this is all about Mich\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python2.7/site-packages/bs4/__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 174 of the file /anaconda/lib/python2.7/runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup          \n",
    "# remove markup \n",
    "example = BeautifulSoup(traindf[\"review\"][0])\n",
    "print traindf[\"review\"][0][550:650]\n",
    "print example.get_text()[550:650]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ## re\n",
    "\n",
    "    [“^[a-zA-Z]” or “[^a-zA-Z]”](https://stackoverflow.com/questions/2790813/regular-expression-a-za-z-or-a-za-z)\n",
    "        ^ outside of the character class (\"[a-zA-Z]\") notes that it is the \"begins with\" operator.\n",
    "        ^ inside of the character negates the specified class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " the obvious message of drugs are bad m kay Visually impressive but of course this is all about Mich\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "# Use regular expressions to do a find-and-replace\n",
    "letters_only = re.sub(\"[^a-zA-Z]\",           # The pattern to search for\n",
    "                      \" \",                   # The pattern to replace it with\n",
    "                      example.get_text() )  # The text to search\n",
    "print letters_only[550:650]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ## build-in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " the obvious message of drugs are bad m kay visually impressive but of course this is all about mich\n"
     ]
    }
   ],
   "source": [
    "print letters_only[550:650].lower()\n",
    "letters_only_list = letters_only[550:650].lower().split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ## nltk\n",
    "\n",
    "        stop words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'i', u'me', u'my', u'myself', u'we', u'our', u'ours', u'ourselves', u'you', u\"you're\"]\n",
      "\n",
      "[u'obvious', u'message', u'drugs', u'bad', u'kay', u'visually', u'impressive', u'course', u'mich']\n"
     ]
    }
   ],
   "source": [
    "#nltk.download()  # Download text data sets, including stop words\n",
    "#nltk.download_shel()\n",
    "from nltk.corpus import stopwords # Import the stop word list\n",
    "print stopwords.words(\"english\")[:10]\n",
    "# remove the stop words from list\n",
    "print \n",
    "print [w for w in letters_only_list if not w in stopwords.words(\"english\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def word_clean(sentence,remove_stopwords=False):\n",
    "    # 1. Remove HTML\n",
    "    review_text = BeautifulSoup(sentence).get_text() \n",
    "    # 2. Remove non-letters        \n",
    "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", review_text) \n",
    "    # 3. Convert to lower case, split into individual words\n",
    "    words = letters_only.lower().split()                             \n",
    "    # 4. Remove stop words\n",
    "    if remove_stopwords:\n",
    "        stops = set(stopwords.words(\"english\"))                   \n",
    "        meaningful_words = [w for w in words if not w in stops]   \n",
    "    # 6. Join \n",
    "    else:\n",
    "        meaningful_words = words\n",
    "    return( \" \".join( meaningful_words ))   \n",
    "\n",
    "traindf.review = traindf.review.apply(word_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction\n",
    "\n",
    "    Sklearn.CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# Initialize the \"CountVectorizer\" object, which is scikit-learn's\n",
    "# bag of words tool.  \n",
    "vectorizer = CountVectorizer(analyzer = \"word\",   \n",
    "                             tokenizer = None,    \n",
    "                             preprocessor = None, \n",
    "                             stop_words = None,   \n",
    "                             max_features = 5000) \n",
    "\n",
    "train_data_features = vectorizer.fit_transform(traindf.review)\n",
    "train_data_features = train_data_features.toarray() # to np array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "# Sum up the counts of each vocabulary word\n",
    "vocab = vectorizer.get_feature_names()\n",
    "dist = np.sum(train_data_features, axis=0)\n",
    "\n",
    "x,y = zip(*sorted(map(list,zip(dist, vocab)),reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1sAAALlCAYAAAAyi/y0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nOECSlcsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12ff355d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (14,13))\n",
    "sns.barplot(x[:50],y[:50]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train-predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = np.concatenate([train_data_features, np.array(traindf[['textblod-polarity','textblod-subjectivity', 'vaderSentiment-compound',\n",
    "            'vaderSentiment-neg','vaderSentiment-neu','vaderSentiment-pos']])],axis = 1)\n",
    "y = np.array(traindf['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2856  842]\n",
      " [ 455 3347]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.77      0.81      3698\n",
      "          1       0.80      0.88      0.84      3802\n",
      "\n",
      "avg / total       0.83      0.83      0.83      7500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.30, random_state=325)\n",
    "\n",
    "rfc = SVC()\n",
    "rfc.fit(X_train,y_train)\n",
    "pred = rfc.predict(X_test)\n",
    "\n",
    "print confusion_matrix(y_test,pred)\n",
    "print '\\n'\n",
    "print classification_report(y_test,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3131  567]\n",
      " [ 621 3181]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.85      0.84      3698\n",
      "          1       0.85      0.84      0.84      3802\n",
      "\n",
      "avg / total       0.84      0.84      0.84      7500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.30, random_state=325)\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=150)\n",
    "rfc.fit(X_train,y_train)\n",
    "pred = rfc.predict(X_test)\n",
    "\n",
    "print confusion_matrix(y_test,pred)\n",
    "print '\\n'\n",
    "print classification_report(y_test,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3162  536]\n",
      " [ 577 3225]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.86      0.85      3698\n",
      "          1       0.86      0.85      0.85      3802\n",
      "\n",
      "avg / total       0.85      0.85      0.85      7500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "NBC = MultinomialNB()\n",
    "NBC.fit(X_train[:,:-6],y_train)\n",
    "pred = NBC.predict(X_test[:,:-6])\n",
    "\n",
    "print confusion_matrix(y_test,pred)\n",
    "print '\\n'\n",
    "print classification_report(y_test,pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Distributed Word Vectors\n",
    "\n",
    "   Introduced by Google, which will take a text corpus as input and produces the word vectors as output. Intutively, if two words have similar defination, their vector should be close (cosine distance should be small)\n",
    "   \n",
    "        word2vec(https://code.google.com/archive/p/word2vec/) | gensim | cython\n",
    "        \n",
    "   **To train Word2Vec it is better not to remove stop words because the algorithm relies on the broader context of the sentence in order to produce high-quality word vectors**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# let's train a vector based on original traindata corpus\n",
    "originalreview = pd.read_csv( \"data/labeledTrainData.tsv\", header=0, \n",
    "                             delimiter=\"\\t\", quoting=3 , encoding = 'utf8').review\n",
    "sentences = map(lambda var: TextBlob(var).sentences, originalreview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sentencesflat = []\n",
    "for sen in sentences:\n",
    "    sentencesflat += map(lambda var: (re.sub(\"[^a-zA-Z]\",\" \", str(var))).strip().split(),sen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-04-02 17:42:54,984 : INFO : collecting all words and their counts\n",
      "2018-04-02 17:42:54,985 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2018-04-02 17:42:55,061 : INFO : PROGRESS: at sentence #10000, processed 229498 words, keeping 20367 word types\n",
      "2018-04-02 17:42:55,111 : INFO : PROGRESS: at sentence #20000, processed 459536 words, keeping 29054 word types\n",
      "2018-04-02 17:42:55,160 : INFO : PROGRESS: at sentence #30000, processed 682841 words, keeping 35246 word types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-04-02 17:42:55,217 : INFO : PROGRESS: at sentence #40000, processed 913402 words, keeping 40618 word types\n",
      "2018-04-02 17:42:55,264 : INFO : PROGRESS: at sentence #50000, processed 1136576 words, keeping 44896 word types\n",
      "2018-04-02 17:42:55,324 : INFO : PROGRESS: at sentence #60000, processed 1361750 words, keeping 48733 word types\n",
      "2018-04-02 17:42:55,371 : INFO : PROGRESS: at sentence #70000, processed 1588810 words, keeping 52077 word types\n",
      "2018-04-02 17:42:55,417 : INFO : PROGRESS: at sentence #80000, processed 1811911 words, keeping 55122 word types\n",
      "2018-04-02 17:42:55,467 : INFO : PROGRESS: at sentence #90000, processed 2039887 words, keeping 58176 word types\n",
      "2018-04-02 17:42:55,517 : INFO : PROGRESS: at sentence #100000, processed 2265530 words, keeping 60922 word types\n",
      "2018-04-02 17:42:55,574 : INFO : PROGRESS: at sentence #110000, processed 2488946 words, keeping 63448 word types\n",
      "2018-04-02 17:42:55,639 : INFO : PROGRESS: at sentence #120000, processed 2714874 words, keeping 66026 word types\n",
      "2018-04-02 17:42:55,708 : INFO : PROGRESS: at sentence #130000, processed 2944511 words, keeping 68295 word types\n",
      "2018-04-02 17:42:55,759 : INFO : PROGRESS: at sentence #140000, processed 3160797 words, keeping 70246 word types\n",
      "2018-04-02 17:42:55,805 : INFO : PROGRESS: at sentence #150000, processed 3390164 words, keeping 72447 word types\n",
      "2018-04-02 17:42:55,852 : INFO : PROGRESS: at sentence #160000, processed 3616854 words, keeping 74515 word types\n",
      "2018-04-02 17:42:55,898 : INFO : PROGRESS: at sentence #170000, processed 3844038 words, keeping 76390 word types\n",
      "2018-04-02 17:42:55,943 : INFO : PROGRESS: at sentence #180000, processed 4068531 words, keeping 78190 word types\n",
      "2018-04-02 17:42:55,995 : INFO : PROGRESS: at sentence #190000, processed 4297560 words, keeping 79920 word types\n",
      "2018-04-02 17:42:56,047 : INFO : PROGRESS: at sentence #200000, processed 4525521 words, keeping 81694 word types\n",
      "2018-04-02 17:42:56,101 : INFO : PROGRESS: at sentence #210000, processed 4750833 words, keeping 83457 word types\n",
      "2018-04-02 17:42:56,155 : INFO : PROGRESS: at sentence #220000, processed 4980092 words, keeping 85117 word types\n",
      "2018-04-02 17:42:56,201 : INFO : PROGRESS: at sentence #230000, processed 5206533 words, keeping 86742 word types\n",
      "2018-04-02 17:42:56,250 : INFO : PROGRESS: at sentence #240000, processed 5438162 words, keeping 88326 word types\n",
      "2018-04-02 17:42:56,293 : INFO : PROGRESS: at sentence #250000, processed 5656071 words, keeping 89895 word types\n",
      "2018-04-02 17:42:56,340 : INFO : PROGRESS: at sentence #260000, processed 5879737 words, keeping 91382 word types\n",
      "2018-04-02 17:42:56,374 : INFO : collected 92345 word types from a corpus of 6023662 raw words and 266551 sentences\n",
      "2018-04-02 17:42:56,375 : INFO : Loading a fresh vocabulary\n",
      "2018-04-02 17:42:56,454 : INFO : min_count=40 retains 8941 unique words (9% of original 92345, drops 83404)\n",
      "2018-04-02 17:42:56,455 : INFO : min_count=40 leaves 5593217 word corpus (92% of original 6023662, drops 430445)\n",
      "2018-04-02 17:42:56,484 : INFO : deleting the raw counts dictionary of 92345 items\n",
      "2018-04-02 17:42:56,488 : INFO : sample=0.001 downsamples 48 most-common words\n",
      "2018-04-02 17:42:56,490 : INFO : downsampling leaves estimated 4131188 word corpus (73.9% of prior 5593217)\n",
      "2018-04-02 17:42:56,535 : INFO : estimated required memory for 8941 words and 300 dimensions: 25928900 bytes\n",
      "2018-04-02 17:42:56,536 : INFO : resetting layer weights\n",
      "2018-04-02 17:42:56,800 : INFO : training model with 4 workers on 8941 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=10\n",
      "2018-04-02 17:42:58,053 : INFO : EPOCH 1 - PROGRESS: at 0.81% examples, 27385 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-02 17:42:59,330 : INFO : EPOCH 1 - PROGRESS: at 2.12% examples, 35237 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:43:00,893 : INFO : EPOCH 1 - PROGRESS: at 3.43% examples, 35129 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-02 17:43:02,588 : INFO : EPOCH 1 - PROGRESS: at 4.74% examples, 34285 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:43:03,590 : INFO : EPOCH 1 - PROGRESS: at 5.90% examples, 36246 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-02 17:43:04,897 : INFO : EPOCH 1 - PROGRESS: at 6.72% examples, 34639 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:43:06,962 : INFO : EPOCH 1 - PROGRESS: at 8.02% examples, 33012 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:43:08,443 : INFO : EPOCH 1 - PROGRESS: at 9.37% examples, 33516 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:43:09,519 : INFO : EPOCH 1 - PROGRESS: at 10.04% examples, 32837 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-02 17:43:10,704 : INFO : EPOCH 1 - PROGRESS: at 10.69% examples, 32015 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:43:11,736 : INFO : EPOCH 1 - PROGRESS: at 11.37% examples, 31631 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-02 17:43:13,159 : INFO : EPOCH 1 - PROGRESS: at 12.03% examples, 30549 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:43:14,288 : INFO : EPOCH 1 - PROGRESS: at 12.68% examples, 30145 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:43:15,556 : INFO : EPOCH 1 - PROGRESS: at 13.33% examples, 29570 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:43:16,761 : INFO : EPOCH 1 - PROGRESS: at 13.97% examples, 29142 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-02 17:43:18,274 : INFO : EPOCH 1 - PROGRESS: at 15.25% examples, 29637 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:43:19,382 : INFO : EPOCH 1 - PROGRESS: at 16.25% examples, 29992 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:43:20,658 : INFO : EPOCH 1 - PROGRESS: at 17.22% examples, 30119 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-02 17:43:21,927 : INFO : EPOCH 1 - PROGRESS: at 18.61% examples, 30769 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:43:23,225 : INFO : EPOCH 1 - PROGRESS: at 19.93% examples, 31323 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:43:24,614 : INFO : EPOCH 1 - PROGRESS: at 21.26% examples, 31728 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:43:25,642 : INFO : EPOCH 1 - PROGRESS: at 22.43% examples, 32269 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-02 17:43:26,704 : INFO : EPOCH 1 - PROGRESS: at 22.62% examples, 31341 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:43:28,550 : INFO : EPOCH 1 - PROGRESS: at 23.95% examples, 31250 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-02 17:43:29,700 : INFO : EPOCH 1 - PROGRESS: at 24.95% examples, 31411 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:43:30,714 : INFO : EPOCH 1 - PROGRESS: at 25.59% examples, 31280 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-02 17:43:31,771 : INFO : EPOCH 1 - PROGRESS: at 26.38% examples, 31319 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-02 17:43:32,774 : INFO : EPOCH 1 - PROGRESS: at 27.07% examples, 31201 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:43:34,207 : INFO : EPOCH 1 - PROGRESS: at 27.90% examples, 30926 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:43:35,348 : INFO : EPOCH 1 - PROGRESS: at 28.91% examples, 31075 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:43:36,435 : INFO : EPOCH 1 - PROGRESS: at 29.77% examples, 31086 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:43:37,725 : INFO : EPOCH 1 - PROGRESS: at 30.60% examples, 30949 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:43:38,726 : INFO : EPOCH 1 - PROGRESS: at 31.37% examples, 31018 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:43:39,915 : INFO : EPOCH 1 - PROGRESS: at 32.21% examples, 30971 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-02 17:43:41,076 : INFO : EPOCH 1 - PROGRESS: at 33.00% examples, 30913 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-02 17:43:42,362 : INFO : EPOCH 1 - PROGRESS: at 33.89% examples, 30788 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:43:43,506 : INFO : EPOCH 1 - PROGRESS: at 34.91% examples, 30915 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:43:44,588 : INFO : EPOCH 1 - PROGRESS: at 35.71% examples, 30941 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:43:45,785 : INFO : EPOCH 1 - PROGRESS: at 36.56% examples, 30883 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:43:46,913 : INFO : EPOCH 1 - PROGRESS: at 37.52% examples, 31008 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:43:48,294 : INFO : EPOCH 1 - PROGRESS: at 38.56% examples, 30977 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:43:49,398 : INFO : EPOCH 1 - PROGRESS: at 39.53% examples, 31108 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-02 17:43:50,496 : INFO : EPOCH 1 - PROGRESS: at 40.37% examples, 31113 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:43:51,674 : INFO : EPOCH 1 - PROGRESS: at 41.22% examples, 31067 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:43:52,731 : INFO : EPOCH 1 - PROGRESS: at 42.23% examples, 31216 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:43:54,037 : INFO : EPOCH 1 - PROGRESS: at 43.23% examples, 31221 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:43:55,156 : INFO : EPOCH 1 - PROGRESS: at 44.35% examples, 31444 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:43:56,243 : INFO : EPOCH 1 - PROGRESS: at 45.19% examples, 31441 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:43:57,284 : INFO : EPOCH 1 - PROGRESS: at 46.14% examples, 31579 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:43:58,610 : INFO : EPOCH 1 - PROGRESS: at 47.13% examples, 31570 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:43:59,903 : INFO : EPOCH 1 - PROGRESS: at 48.44% examples, 31794 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:44:00,942 : INFO : EPOCH 1 - PROGRESS: at 49.72% examples, 32030 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:44:02,340 : INFO : EPOCH 1 - PROGRESS: at 50.54% examples, 31867 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:44:03,422 : INFO : EPOCH 1 - PROGRESS: at 51.56% examples, 31969 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:44:04,582 : INFO : EPOCH 1 - PROGRESS: at 52.58% examples, 32028 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:44:05,846 : INFO : EPOCH 1 - PROGRESS: at 53.87% examples, 32233 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-02 17:44:07,096 : INFO : EPOCH 1 - PROGRESS: at 55.17% examples, 32439 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-02 17:44:08,335 : INFO : EPOCH 1 - PROGRESS: at 56.53% examples, 32641 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:44:09,537 : INFO : EPOCH 1 - PROGRESS: at 57.86% examples, 32854 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:44:10,785 : INFO : EPOCH 1 - PROGRESS: at 59.12% examples, 33039 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:44:12,034 : INFO : EPOCH 1 - PROGRESS: at 60.47% examples, 33217 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:44:13,290 : INFO : EPOCH 1 - PROGRESS: at 61.82% examples, 33390 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:44:14,517 : INFO : EPOCH 1 - PROGRESS: at 63.12% examples, 33571 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:44:15,524 : INFO : EPOCH 1 - PROGRESS: at 64.27% examples, 33749 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:44:16,739 : INFO : EPOCH 1 - PROGRESS: at 65.47% examples, 33839 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:44:17,991 : INFO : EPOCH 1 - PROGRESS: at 66.78% examples, 33993 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-02 17:44:19,242 : INFO : EPOCH 1 - PROGRESS: at 68.09% examples, 34146 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:44:20,267 : INFO : EPOCH 1 - PROGRESS: at 69.24% examples, 34300 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:44:21,277 : INFO : EPOCH 1 - PROGRESS: at 70.19% examples, 34377 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:44:22,364 : INFO : EPOCH 1 - PROGRESS: at 71.35% examples, 34501 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-02 17:44:23,423 : INFO : EPOCH 1 - PROGRESS: at 72.52% examples, 34632 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-02 17:44:24,513 : INFO : EPOCH 1 - PROGRESS: at 73.68% examples, 34748 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:44:25,677 : INFO : EPOCH 1 - PROGRESS: at 74.80% examples, 34830 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:44:26,691 : INFO : EPOCH 1 - PROGRESS: at 75.99% examples, 34969 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-02 17:44:27,840 : INFO : EPOCH 1 - PROGRESS: at 77.18% examples, 35057 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:44:28,873 : INFO : EPOCH 1 - PROGRESS: at 78.32% examples, 35181 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:44:30,037 : INFO : EPOCH 1 - PROGRESS: at 79.43% examples, 35254 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:44:31,051 : INFO : EPOCH 1 - PROGRESS: at 80.61% examples, 35379 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:44:32,170 : INFO : EPOCH 1 - PROGRESS: at 81.76% examples, 35469 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:44:33,263 : INFO : EPOCH 1 - PROGRESS: at 82.86% examples, 35564 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:44:34,390 : INFO : EPOCH 1 - PROGRESS: at 84.06% examples, 35644 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:44:35,406 : INFO : EPOCH 1 - PROGRESS: at 85.19% examples, 35760 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:44:36,537 : INFO : EPOCH 1 - PROGRESS: at 86.36% examples, 35834 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-02 17:44:37,672 : INFO : EPOCH 1 - PROGRESS: at 87.46% examples, 35905 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-02 17:44:38,777 : INFO : EPOCH 1 - PROGRESS: at 88.62% examples, 35988 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:44:39,803 : INFO : EPOCH 1 - PROGRESS: at 89.76% examples, 36093 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:44:40,830 : INFO : EPOCH 1 - PROGRESS: at 90.77% examples, 36131 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-02 17:44:41,969 : INFO : EPOCH 1 - PROGRESS: at 92.00% examples, 36194 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:44:43,212 : INFO : EPOCH 1 - PROGRESS: at 93.37% examples, 36286 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:44:44,445 : INFO : EPOCH 1 - PROGRESS: at 94.74% examples, 36380 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:44:45,691 : INFO : EPOCH 1 - PROGRESS: at 96.05% examples, 36464 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:44:46,930 : INFO : EPOCH 1 - PROGRESS: at 97.36% examples, 36550 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:44:48,174 : INFO : EPOCH 1 - PROGRESS: at 98.73% examples, 36636 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:44:48,829 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-04-02 17:44:48,996 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-02 17:44:49,025 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-02 17:44:49,031 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-02 17:44:49,032 : INFO : EPOCH - 1 : training on 6023662 raw words (4130837 effective words) took 112.2s, 36809 effective words/s\n",
      "2018-04-02 17:44:50,270 : INFO : EPOCH 2 - PROGRESS: at 0.81% examples, 27733 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-02 17:44:51,513 : INFO : EPOCH 2 - PROGRESS: at 2.12% examples, 35825 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:44:52,735 : INFO : EPOCH 2 - PROGRESS: at 3.43% examples, 38757 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:44:53,962 : INFO : EPOCH 2 - PROGRESS: at 4.74% examples, 40221 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:44:55,237 : INFO : EPOCH 2 - PROGRESS: at 6.07% examples, 40742 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-02 17:44:56,483 : INFO : EPOCH 2 - PROGRESS: at 7.35% examples, 41318 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:44:57,728 : INFO : EPOCH 2 - PROGRESS: at 8.70% examples, 41728 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:44:58,981 : INFO : EPOCH 2 - PROGRESS: at 10.04% examples, 41987 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-02 17:45:00,213 : INFO : EPOCH 2 - PROGRESS: at 11.33% examples, 42227 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:45:01,447 : INFO : EPOCH 2 - PROGRESS: at 12.68% examples, 42439 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:45:02,672 : INFO : EPOCH 2 - PROGRESS: at 13.93% examples, 42631 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:45:03,885 : INFO : EPOCH 2 - PROGRESS: at 15.25% examples, 42816 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-02 17:45:05,121 : INFO : EPOCH 2 - PROGRESS: at 16.58% examples, 42924 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:45:06,342 : INFO : EPOCH 2 - PROGRESS: at 17.87% examples, 43058 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:45:07,589 : INFO : EPOCH 2 - PROGRESS: at 19.25% examples, 43106 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:45:08,834 : INFO : EPOCH 2 - PROGRESS: at 20.58% examples, 43152 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:45:10,076 : INFO : EPOCH 2 - PROGRESS: at 21.93% examples, 43204 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-02 17:45:11,310 : INFO : EPOCH 2 - PROGRESS: at 23.28% examples, 43272 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-02 17:45:12,527 : INFO : EPOCH 2 - PROGRESS: at 24.61% examples, 43373 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:45:13,774 : INFO : EPOCH 2 - PROGRESS: at 25.92% examples, 43412 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:45:14,999 : INFO : EPOCH 2 - PROGRESS: at 27.24% examples, 43465 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:45:16,230 : INFO : EPOCH 2 - PROGRESS: at 28.56% examples, 43517 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:45:17,468 : INFO : EPOCH 2 - PROGRESS: at 29.93% examples, 43548 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:45:18,692 : INFO : EPOCH 2 - PROGRESS: at 31.20% examples, 43594 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-02 17:45:19,934 : INFO : EPOCH 2 - PROGRESS: at 32.54% examples, 43608 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-02 17:45:21,156 : INFO : EPOCH 2 - PROGRESS: at 33.89% examples, 43646 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:45:22,402 : INFO : EPOCH 2 - PROGRESS: at 35.23% examples, 43664 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-02 17:45:23,619 : INFO : EPOCH 2 - PROGRESS: at 36.56% examples, 43722 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:45:24,866 : INFO : EPOCH 2 - PROGRESS: at 37.88% examples, 43736 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:45:26,100 : INFO : EPOCH 2 - PROGRESS: at 39.20% examples, 43764 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:45:27,329 : INFO : EPOCH 2 - PROGRESS: at 40.55% examples, 43797 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:45:28,573 : INFO : EPOCH 2 - PROGRESS: at 41.87% examples, 43802 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:45:29,778 : INFO : EPOCH 2 - PROGRESS: at 43.23% examples, 43850 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:45:30,995 : INFO : EPOCH 2 - PROGRESS: at 44.51% examples, 43880 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:45:32,219 : INFO : EPOCH 2 - PROGRESS: at 45.83% examples, 43902 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:45:33,457 : INFO : EPOCH 2 - PROGRESS: at 47.13% examples, 43916 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-02 17:45:34,707 : INFO : EPOCH 2 - PROGRESS: at 48.45% examples, 43917 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:45:35,941 : INFO : EPOCH 2 - PROGRESS: at 49.87% examples, 43932 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-02 17:45:37,167 : INFO : EPOCH 2 - PROGRESS: at 51.22% examples, 43955 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:45:38,393 : INFO : EPOCH 2 - PROGRESS: at 52.58% examples, 43974 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:45:39,690 : INFO : EPOCH 2 - PROGRESS: at 53.85% examples, 43924 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:45:40,960 : INFO : EPOCH 2 - PROGRESS: at 55.17% examples, 43910 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:45:42,197 : INFO : EPOCH 2 - PROGRESS: at 56.49% examples, 43919 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:45:43,411 : INFO : EPOCH 2 - PROGRESS: at 57.86% examples, 43943 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:45:44,668 : INFO : EPOCH 2 - PROGRESS: at 59.12% examples, 43932 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:45:45,894 : INFO : EPOCH 2 - PROGRESS: at 60.47% examples, 43943 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:45:47,154 : INFO : EPOCH 2 - PROGRESS: at 61.82% examples, 43942 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-02 17:45:48,388 : INFO : EPOCH 2 - PROGRESS: at 63.12% examples, 43953 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:45:49,626 : INFO : EPOCH 2 - PROGRESS: at 64.44% examples, 43961 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:45:50,886 : INFO : EPOCH 2 - PROGRESS: at 65.78% examples, 43953 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:45:52,165 : INFO : EPOCH 2 - PROGRESS: at 67.10% examples, 43933 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:45:53,414 : INFO : EPOCH 2 - PROGRESS: at 68.43% examples, 43937 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:45:54,639 : INFO : EPOCH 2 - PROGRESS: at 69.75% examples, 43952 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-02 17:45:55,879 : INFO : EPOCH 2 - PROGRESS: at 71.03% examples, 43957 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:45:57,084 : INFO : EPOCH 2 - PROGRESS: at 72.36% examples, 43984 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:45:58,311 : INFO : EPOCH 2 - PROGRESS: at 73.68% examples, 43998 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:45:59,517 : INFO : EPOCH 2 - PROGRESS: at 74.97% examples, 44015 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:46:00,753 : INFO : EPOCH 2 - PROGRESS: at 76.33% examples, 44020 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:46:01,968 : INFO : EPOCH 2 - PROGRESS: at 77.65% examples, 44038 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:46:03,209 : INFO : EPOCH 2 - PROGRESS: at 78.94% examples, 44037 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-02 17:46:04,435 : INFO : EPOCH 2 - PROGRESS: at 80.27% examples, 44043 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:46:05,703 : INFO : EPOCH 2 - PROGRESS: at 81.60% examples, 44029 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:46:06,965 : INFO : EPOCH 2 - PROGRESS: at 82.86% examples, 44021 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:46:08,186 : INFO : EPOCH 2 - PROGRESS: at 84.21% examples, 44031 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-02 17:46:09,425 : INFO : EPOCH 2 - PROGRESS: at 85.51% examples, 44032 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-02 17:46:10,662 : INFO : EPOCH 2 - PROGRESS: at 86.83% examples, 44037 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:46:11,889 : INFO : EPOCH 2 - PROGRESS: at 88.12% examples, 44048 words/s, in_qsize 8, out_qsize 1\n",
      "2018-04-02 17:46:13,122 : INFO : EPOCH 2 - PROGRESS: at 89.44% examples, 44057 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-02 17:46:14,341 : INFO : EPOCH 2 - PROGRESS: at 90.77% examples, 44067 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:46:15,343 : INFO : EPOCH 2 - PROGRESS: at 92.00% examples, 44109 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-02 17:46:16,599 : INFO : EPOCH 2 - PROGRESS: at 93.37% examples, 44102 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-02 17:46:17,803 : INFO : EPOCH 2 - PROGRESS: at 94.74% examples, 44122 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-02 17:46:19,031 : INFO : EPOCH 2 - PROGRESS: at 96.05% examples, 44126 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:46:20,292 : INFO : EPOCH 2 - PROGRESS: at 97.36% examples, 44114 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:46:21,500 : INFO : EPOCH 2 - PROGRESS: at 98.73% examples, 44133 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:46:22,341 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-04-02 17:46:22,371 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-02 17:46:22,390 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-02 17:46:22,397 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-02 17:46:22,398 : INFO : EPOCH - 2 : training on 6023662 raw words (4131440 effective words) took 93.4s, 44253 effective words/s\n",
      "2018-04-02 17:46:23,607 : INFO : EPOCH 3 - PROGRESS: at 0.81% examples, 28216 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:46:24,820 : INFO : EPOCH 3 - PROGRESS: at 2.12% examples, 36628 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:46:26,051 : INFO : EPOCH 3 - PROGRESS: at 3.43% examples, 39267 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:46:27,318 : INFO : EPOCH 3 - PROGRESS: at 4.74% examples, 40295 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:46:28,551 : INFO : EPOCH 3 - PROGRESS: at 6.07% examples, 41105 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:46:29,782 : INFO : EPOCH 3 - PROGRESS: at 7.35% examples, 41676 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:46:31,010 : INFO : EPOCH 3 - PROGRESS: at 8.70% examples, 42084 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-02 17:46:32,228 : INFO : EPOCH 3 - PROGRESS: at 10.04% examples, 42467 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:46:33,459 : INFO : EPOCH 3 - PROGRESS: at 11.33% examples, 42673 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:46:34,699 : INFO : EPOCH 3 - PROGRESS: at 12.68% examples, 42855 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:46:35,928 : INFO : EPOCH 3 - PROGRESS: at 13.97% examples, 42971 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:46:37,160 : INFO : EPOCH 3 - PROGRESS: at 15.25% examples, 43087 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:46:38,447 : INFO : EPOCH 3 - PROGRESS: at 16.58% examples, 43032 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:46:39,680 : INFO : EPOCH 3 - PROGRESS: at 17.87% examples, 43129 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:46:40,920 : INFO : EPOCH 3 - PROGRESS: at 19.25% examples, 43185 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:46:42,189 : INFO : EPOCH 3 - PROGRESS: at 20.58% examples, 43178 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:46:43,431 : INFO : EPOCH 3 - PROGRESS: at 21.93% examples, 43239 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:46:44,676 : INFO : EPOCH 3 - PROGRESS: at 23.29% examples, 43279 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:46:45,904 : INFO : EPOCH 3 - PROGRESS: at 24.61% examples, 43357 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:46:47,145 : INFO : EPOCH 3 - PROGRESS: at 25.92% examples, 43405 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:46:48,361 : INFO : EPOCH 3 - PROGRESS: at 27.24% examples, 43475 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-02 17:46:49,593 : INFO : EPOCH 3 - PROGRESS: at 28.56% examples, 43524 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:46:50,853 : INFO : EPOCH 3 - PROGRESS: at 29.93% examples, 43519 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:46:52,087 : INFO : EPOCH 3 - PROGRESS: at 31.20% examples, 43555 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-02 17:46:53,291 : INFO : EPOCH 3 - PROGRESS: at 32.54% examples, 43625 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:46:54,531 : INFO : EPOCH 3 - PROGRESS: at 33.87% examples, 43647 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:46:55,752 : INFO : EPOCH 3 - PROGRESS: at 35.23% examples, 43697 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:46:56,975 : INFO : EPOCH 3 - PROGRESS: at 36.56% examples, 43739 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:46:58,207 : INFO : EPOCH 3 - PROGRESS: at 37.86% examples, 43769 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:46:59,436 : INFO : EPOCH 3 - PROGRESS: at 39.20% examples, 43803 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:47:00,665 : INFO : EPOCH 3 - PROGRESS: at 40.55% examples, 43837 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:47:01,896 : INFO : EPOCH 3 - PROGRESS: at 41.87% examples, 43852 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:47:03,068 : INFO : EPOCH 3 - PROGRESS: at 43.23% examples, 43936 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:47:04,319 : INFO : EPOCH 3 - PROGRESS: at 44.51% examples, 43933 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-02 17:47:05,564 : INFO : EPOCH 3 - PROGRESS: at 45.83% examples, 43936 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:47:06,809 : INFO : EPOCH 3 - PROGRESS: at 47.13% examples, 43941 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:47:08,058 : INFO : EPOCH 3 - PROGRESS: at 48.45% examples, 43941 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:47:09,287 : INFO : EPOCH 3 - PROGRESS: at 49.87% examples, 43960 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:47:10,521 : INFO : EPOCH 3 - PROGRESS: at 51.22% examples, 43977 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:47:11,758 : INFO : EPOCH 3 - PROGRESS: at 52.58% examples, 43983 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-02 17:47:12,761 : INFO : EPOCH 3 - PROGRESS: at 53.69% examples, 44051 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:47:13,875 : INFO : EPOCH 3 - PROGRESS: at 54.86% examples, 44028 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:47:14,927 : INFO : EPOCH 3 - PROGRESS: at 55.98% examples, 44065 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:47:16,130 : INFO : EPOCH 3 - PROGRESS: at 57.16% examples, 43969 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:47:17,373 : INFO : EPOCH 3 - PROGRESS: at 58.50% examples, 43968 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:47:18,615 : INFO : EPOCH 3 - PROGRESS: at 59.81% examples, 43970 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:47:19,862 : INFO : EPOCH 3 - PROGRESS: at 61.16% examples, 43973 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:47:21,085 : INFO : EPOCH 3 - PROGRESS: at 62.47% examples, 43990 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:47:22,341 : INFO : EPOCH 3 - PROGRESS: at 63.76% examples, 43989 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-02 17:47:23,590 : INFO : EPOCH 3 - PROGRESS: at 65.12% examples, 43989 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:47:24,831 : INFO : EPOCH 3 - PROGRESS: at 66.46% examples, 43993 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-02 17:47:26,074 : INFO : EPOCH 3 - PROGRESS: at 67.78% examples, 43996 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-02 17:47:27,319 : INFO : EPOCH 3 - PROGRESS: at 69.08% examples, 43996 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:47:28,551 : INFO : EPOCH 3 - PROGRESS: at 70.37% examples, 44004 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:47:29,811 : INFO : EPOCH 3 - PROGRESS: at 71.68% examples, 43998 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:47:31,062 : INFO : EPOCH 3 - PROGRESS: at 73.03% examples, 43992 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:47:32,343 : INFO : EPOCH 3 - PROGRESS: at 74.32% examples, 43968 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:47:33,545 : INFO : EPOCH 3 - PROGRESS: at 75.64% examples, 43994 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:47:34,783 : INFO : EPOCH 3 - PROGRESS: at 77.01% examples, 43998 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:47:36,016 : INFO : EPOCH 3 - PROGRESS: at 78.32% examples, 44006 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:47:37,255 : INFO : EPOCH 3 - PROGRESS: at 79.61% examples, 44008 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:47:38,472 : INFO : EPOCH 3 - PROGRESS: at 80.94% examples, 44018 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-02 17:47:39,747 : INFO : EPOCH 3 - PROGRESS: at 82.22% examples, 44002 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-02 17:47:40,999 : INFO : EPOCH 3 - PROGRESS: at 83.54% examples, 43999 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:47:42,240 : INFO : EPOCH 3 - PROGRESS: at 84.87% examples, 44001 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:47:43,486 : INFO : EPOCH 3 - PROGRESS: at 86.19% examples, 43999 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:47:44,753 : INFO : EPOCH 3 - PROGRESS: at 87.46% examples, 43987 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-02 17:47:45,982 : INFO : EPOCH 3 - PROGRESS: at 88.79% examples, 43997 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:47:47,210 : INFO : EPOCH 3 - PROGRESS: at 90.09% examples, 44007 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:47:48,413 : INFO : EPOCH 3 - PROGRESS: at 91.47% examples, 44024 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:47:49,630 : INFO : EPOCH 3 - PROGRESS: at 92.86% examples, 44036 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:47:50,891 : INFO : EPOCH 3 - PROGRESS: at 94.25% examples, 44028 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:47:52,112 : INFO : EPOCH 3 - PROGRESS: at 95.58% examples, 44041 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:47:53,361 : INFO : EPOCH 3 - PROGRESS: at 96.86% examples, 44035 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:47:54,573 : INFO : EPOCH 3 - PROGRESS: at 98.23% examples, 44051 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:47:55,618 : INFO : EPOCH 3 - PROGRESS: at 99.49% examples, 44103 words/s, in_qsize 3, out_qsize 1\n",
      "2018-04-02 17:47:55,619 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-04-02 17:47:55,762 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-02 17:47:55,817 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-02 17:47:55,864 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-02 17:47:55,864 : INFO : EPOCH - 3 : training on 6023662 raw words (4131645 effective words) took 93.5s, 44206 effective words/s\n",
      "2018-04-02 17:47:57,088 : INFO : EPOCH 4 - PROGRESS: at 0.81% examples, 27993 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:47:58,298 : INFO : EPOCH 4 - PROGRESS: at 2.12% examples, 36543 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:47:59,525 : INFO : EPOCH 4 - PROGRESS: at 3.43% examples, 39161 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-02 17:48:00,766 : INFO : EPOCH 4 - PROGRESS: at 4.74% examples, 40427 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:48:01,991 : INFO : EPOCH 4 - PROGRESS: at 6.07% examples, 41256 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:48:03,223 : INFO : EPOCH 4 - PROGRESS: at 7.35% examples, 41839 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:48:04,461 : INFO : EPOCH 4 - PROGRESS: at 8.70% examples, 42203 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:48:05,712 : INFO : EPOCH 4 - PROGRESS: at 10.04% examples, 42413 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:48:06,950 : INFO : EPOCH 4 - PROGRESS: at 11.37% examples, 42604 words/s, in_qsize 8, out_qsize 1\n",
      "2018-04-02 17:48:08,178 : INFO : EPOCH 4 - PROGRESS: at 12.68% examples, 42793 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:48:09,392 : INFO : EPOCH 4 - PROGRESS: at 13.93% examples, 42990 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:48:10,626 : INFO : EPOCH 4 - PROGRESS: at 15.25% examples, 43093 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:48:11,865 : INFO : EPOCH 4 - PROGRESS: at 16.58% examples, 43167 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-02 17:48:13,102 : INFO : EPOCH 4 - PROGRESS: at 17.87% examples, 43239 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:48:14,347 : INFO : EPOCH 4 - PROGRESS: at 19.25% examples, 43277 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:48:15,605 : INFO : EPOCH 4 - PROGRESS: at 20.58% examples, 43286 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:48:16,823 : INFO : EPOCH 4 - PROGRESS: at 21.93% examples, 43386 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:48:18,090 : INFO : EPOCH 4 - PROGRESS: at 23.29% examples, 43376 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-02 17:48:19,312 : INFO : EPOCH 4 - PROGRESS: at 24.61% examples, 43463 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:48:20,578 : INFO : EPOCH 4 - PROGRESS: at 25.92% examples, 43466 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:48:21,800 : INFO : EPOCH 4 - PROGRESS: at 27.25% examples, 43533 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:48:23,040 : INFO : EPOCH 4 - PROGRESS: at 28.56% examples, 43564 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-02 17:48:24,268 : INFO : EPOCH 4 - PROGRESS: at 29.93% examples, 43603 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:48:25,507 : INFO : EPOCH 4 - PROGRESS: at 31.20% examples, 43628 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:48:26,730 : INFO : EPOCH 4 - PROGRESS: at 32.54% examples, 43667 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:48:27,970 : INFO : EPOCH 4 - PROGRESS: at 33.89% examples, 43678 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:48:29,222 : INFO : EPOCH 4 - PROGRESS: at 35.22% examples, 43688 words/s, in_qsize 8, out_qsize 1\n",
      "2018-04-02 17:48:30,448 : INFO : EPOCH 4 - PROGRESS: at 36.56% examples, 43732 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:48:31,678 : INFO : EPOCH 4 - PROGRESS: at 37.88% examples, 43758 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:48:32,934 : INFO : EPOCH 4 - PROGRESS: at 39.20% examples, 43759 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-02 17:48:34,147 : INFO : EPOCH 4 - PROGRESS: at 40.55% examples, 43806 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:48:35,397 : INFO : EPOCH 4 - PROGRESS: at 41.90% examples, 43801 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:48:36,591 : INFO : EPOCH 4 - PROGRESS: at 43.23% examples, 43858 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:48:37,874 : INFO : EPOCH 4 - PROGRESS: at 44.51% examples, 43820 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:48:39,157 : INFO : EPOCH 4 - PROGRESS: at 45.83% examples, 43786 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:48:40,446 : INFO : EPOCH 4 - PROGRESS: at 47.13% examples, 43751 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-02 17:48:41,653 : INFO : EPOCH 4 - PROGRESS: at 48.45% examples, 43797 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:48:42,847 : INFO : EPOCH 4 - PROGRESS: at 49.87% examples, 43851 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:48:44,056 : INFO : EPOCH 4 - PROGRESS: at 51.22% examples, 43893 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:48:45,299 : INFO : EPOCH 4 - PROGRESS: at 52.58% examples, 43896 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:48:46,554 : INFO : EPOCH 4 - PROGRESS: at 53.85% examples, 43887 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:48:47,814 : INFO : EPOCH 4 - PROGRESS: at 55.17% examples, 43878 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:48:49,041 : INFO : EPOCH 4 - PROGRESS: at 56.53% examples, 43896 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:48:50,264 : INFO : EPOCH 4 - PROGRESS: at 57.86% examples, 43911 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-02 17:48:51,498 : INFO : EPOCH 4 - PROGRESS: at 59.12% examples, 43918 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-02 17:48:52,734 : INFO : EPOCH 4 - PROGRESS: at 60.47% examples, 43927 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:48:53,973 : INFO : EPOCH 4 - PROGRESS: at 61.82% examples, 43941 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:48:55,219 : INFO : EPOCH 4 - PROGRESS: at 63.12% examples, 43947 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-02 17:48:56,449 : INFO : EPOCH 4 - PROGRESS: at 64.44% examples, 43958 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:48:57,690 : INFO : EPOCH 4 - PROGRESS: at 65.78% examples, 43963 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:48:58,933 : INFO : EPOCH 4 - PROGRESS: at 67.10% examples, 43966 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-02 17:49:00,162 : INFO : EPOCH 4 - PROGRESS: at 68.43% examples, 43985 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-02 17:49:01,393 : INFO : EPOCH 4 - PROGRESS: at 69.74% examples, 43993 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:49:02,413 : INFO : EPOCH 4 - PROGRESS: at 70.84% examples, 44044 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:49:03,633 : INFO : EPOCH 4 - PROGRESS: at 72.18% examples, 44057 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:49:04,879 : INFO : EPOCH 4 - PROGRESS: at 73.52% examples, 44055 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:49:06,187 : INFO : EPOCH 4 - PROGRESS: at 74.80% examples, 44012 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:49:07,430 : INFO : EPOCH 4 - PROGRESS: at 76.14% examples, 44011 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:49:08,663 : INFO : EPOCH 4 - PROGRESS: at 77.50% examples, 44018 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:49:09,909 : INFO : EPOCH 4 - PROGRESS: at 78.79% examples, 44014 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:49:11,137 : INFO : EPOCH 4 - PROGRESS: at 80.11% examples, 44020 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:49:12,415 : INFO : EPOCH 4 - PROGRESS: at 81.43% examples, 43999 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:49:13,660 : INFO : EPOCH 4 - PROGRESS: at 82.71% examples, 44002 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:49:14,875 : INFO : EPOCH 4 - PROGRESS: at 84.06% examples, 44018 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:49:16,100 : INFO : EPOCH 4 - PROGRESS: at 85.35% examples, 44026 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-02 17:49:17,339 : INFO : EPOCH 4 - PROGRESS: at 86.68% examples, 44027 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:49:18,587 : INFO : EPOCH 4 - PROGRESS: at 87.97% examples, 44029 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-02 17:49:19,821 : INFO : EPOCH 4 - PROGRESS: at 89.31% examples, 44035 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-02 17:49:21,045 : INFO : EPOCH 4 - PROGRESS: at 90.59% examples, 44045 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-02 17:49:22,266 : INFO : EPOCH 4 - PROGRESS: at 92.00% examples, 44054 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:49:23,559 : INFO : EPOCH 4 - PROGRESS: at 93.37% examples, 44028 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:49:24,797 : INFO : EPOCH 4 - PROGRESS: at 94.74% examples, 44032 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:49:26,054 : INFO : EPOCH 4 - PROGRESS: at 96.05% examples, 44023 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:49:27,324 : INFO : EPOCH 4 - PROGRESS: at 97.36% examples, 44009 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:49:28,547 : INFO : EPOCH 4 - PROGRESS: at 98.73% examples, 44020 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:49:29,236 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-04-02 17:49:29,298 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-02 17:49:29,341 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-02 17:49:29,381 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-02 17:49:29,382 : INFO : EPOCH - 4 : training on 6023662 raw words (4130350 effective words) took 93.5s, 44169 effective words/s\n",
      "2018-04-02 17:49:30,594 : INFO : EPOCH 5 - PROGRESS: at 0.81% examples, 28273 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:49:31,946 : INFO : EPOCH 5 - PROGRESS: at 2.12% examples, 34622 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:49:33,218 : INFO : EPOCH 5 - PROGRESS: at 3.43% examples, 37403 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:49:34,444 : INFO : EPOCH 5 - PROGRESS: at 4.74% examples, 39133 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-02 17:49:35,701 : INFO : EPOCH 5 - PROGRESS: at 6.07% examples, 40010 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:49:36,953 : INFO : EPOCH 5 - PROGRESS: at 7.35% examples, 40646 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:49:38,165 : INFO : EPOCH 5 - PROGRESS: at 8.70% examples, 41275 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:49:39,377 : INFO : EPOCH 5 - PROGRESS: at 10.04% examples, 41760 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:49:40,607 : INFO : EPOCH 5 - PROGRESS: at 11.33% examples, 42056 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:49:41,818 : INFO : EPOCH 5 - PROGRESS: at 12.68% examples, 42370 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:49:43,046 : INFO : EPOCH 5 - PROGRESS: at 13.93% examples, 42555 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-02 17:49:44,291 : INFO : EPOCH 5 - PROGRESS: at 15.25% examples, 42652 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:49:45,577 : INFO : EPOCH 5 - PROGRESS: at 16.58% examples, 42649 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:49:46,815 : INFO : EPOCH 5 - PROGRESS: at 17.87% examples, 42756 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:49:48,044 : INFO : EPOCH 5 - PROGRESS: at 19.25% examples, 42866 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:49:49,307 : INFO : EPOCH 5 - PROGRESS: at 20.58% examples, 42892 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:49:50,550 : INFO : EPOCH 5 - PROGRESS: at 21.93% examples, 42964 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:49:51,775 : INFO : EPOCH 5 - PROGRESS: at 23.28% examples, 43059 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-02 17:49:53,017 : INFO : EPOCH 5 - PROGRESS: at 24.61% examples, 43124 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:49:54,277 : INFO : EPOCH 5 - PROGRESS: at 25.92% examples, 43156 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-02 17:49:55,550 : INFO : EPOCH 5 - PROGRESS: at 27.24% examples, 43145 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:49:56,836 : INFO : EPOCH 5 - PROGRESS: at 28.56% examples, 43127 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:49:58,072 : INFO : EPOCH 5 - PROGRESS: at 29.93% examples, 43174 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:49:59,355 : INFO : EPOCH 5 - PROGRESS: at 31.20% examples, 43155 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:50:00,609 : INFO : EPOCH 5 - PROGRESS: at 32.54% examples, 43177 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:50:01,844 : INFO : EPOCH 5 - PROGRESS: at 33.87% examples, 43223 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:50:03,073 : INFO : EPOCH 5 - PROGRESS: at 35.23% examples, 43275 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:50:04,305 : INFO : EPOCH 5 - PROGRESS: at 36.56% examples, 43326 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:50:05,322 : INFO : EPOCH 5 - PROGRESS: at 37.69% examples, 43434 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:50:06,381 : INFO : EPOCH 5 - PROGRESS: at 38.88% examples, 43495 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:50:07,413 : INFO : EPOCH 5 - PROGRESS: at 39.20% examples, 42674 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:50:08,638 : INFO : EPOCH 5 - PROGRESS: at 40.55% examples, 42739 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-02 17:50:09,854 : INFO : EPOCH 5 - PROGRESS: at 41.87% examples, 42804 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:50:11,056 : INFO : EPOCH 5 - PROGRESS: at 43.23% examples, 42883 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-02 17:50:12,071 : INFO : EPOCH 5 - PROGRESS: at 44.35% examples, 42986 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:50:13,191 : INFO : EPOCH 5 - PROGRESS: at 45.50% examples, 42977 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-02 17:50:14,281 : INFO : EPOCH 5 - PROGRESS: at 46.64% examples, 43005 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:50:15,426 : INFO : EPOCH 5 - PROGRESS: at 47.77% examples, 42979 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:50:16,429 : INFO : EPOCH 5 - PROGRESS: at 49.06% examples, 43081 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:50:17,547 : INFO : EPOCH 5 - PROGRESS: at 50.21% examples, 43078 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:50:18,616 : INFO : EPOCH 5 - PROGRESS: at 51.22% examples, 42982 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-02 17:50:19,860 : INFO : EPOCH 5 - PROGRESS: at 52.58% examples, 43006 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:50:21,094 : INFO : EPOCH 5 - PROGRESS: at 53.85% examples, 43037 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:50:22,113 : INFO : EPOCH 5 - PROGRESS: at 55.03% examples, 43115 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:50:23,247 : INFO : EPOCH 5 - PROGRESS: at 56.17% examples, 43103 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:50:24,277 : INFO : EPOCH 5 - PROGRESS: at 57.32% examples, 43161 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-02 17:50:25,470 : INFO : EPOCH 5 - PROGRESS: at 58.50% examples, 43097 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:50:26,717 : INFO : EPOCH 5 - PROGRESS: at 59.81% examples, 43111 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-02 17:50:27,972 : INFO : EPOCH 5 - PROGRESS: at 61.16% examples, 43124 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-02 17:50:29,232 : INFO : EPOCH 5 - PROGRESS: at 62.47% examples, 43127 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-02 17:50:30,492 : INFO : EPOCH 5 - PROGRESS: at 63.76% examples, 43138 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-02 17:50:31,743 : INFO : EPOCH 5 - PROGRESS: at 65.12% examples, 43154 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:50:33,002 : INFO : EPOCH 5 - PROGRESS: at 66.46% examples, 43164 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:50:34,339 : INFO : EPOCH 5 - PROGRESS: at 67.75% examples, 43122 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:50:35,639 : INFO : EPOCH 5 - PROGRESS: at 69.07% examples, 43099 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-02 17:50:36,938 : INFO : EPOCH 5 - PROGRESS: at 70.37% examples, 43083 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-02 17:50:38,141 : INFO : EPOCH 5 - PROGRESS: at 71.36% examples, 42929 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-02 17:50:39,161 : INFO : EPOCH 5 - PROGRESS: at 72.52% examples, 42988 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:50:40,337 : INFO : EPOCH 5 - PROGRESS: at 73.68% examples, 42948 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:50:41,445 : INFO : EPOCH 5 - PROGRESS: at 74.65% examples, 42858 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:50:42,726 : INFO : EPOCH 5 - PROGRESS: at 75.99% examples, 42855 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:50:43,988 : INFO : EPOCH 5 - PROGRESS: at 77.34% examples, 42866 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:50:45,207 : INFO : EPOCH 5 - PROGRESS: at 78.63% examples, 42900 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-02 17:50:46,435 : INFO : EPOCH 5 - PROGRESS: at 79.94% examples, 42926 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:50:47,664 : INFO : EPOCH 5 - PROGRESS: at 81.27% examples, 42948 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:50:48,913 : INFO : EPOCH 5 - PROGRESS: at 82.56% examples, 42967 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:50:50,113 : INFO : EPOCH 5 - PROGRESS: at 83.88% examples, 43006 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-02 17:50:51,139 : INFO : EPOCH 5 - PROGRESS: at 84.87% examples, 42967 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:50:52,182 : INFO : EPOCH 5 - PROGRESS: at 86.03% examples, 43005 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-02 17:50:53,307 : INFO : EPOCH 5 - PROGRESS: at 87.15% examples, 42995 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-02 17:50:54,326 : INFO : EPOCH 5 - PROGRESS: at 88.27% examples, 43044 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-02 17:50:55,498 : INFO : EPOCH 5 - PROGRESS: at 89.44% examples, 43017 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:50:56,533 : INFO : EPOCH 5 - PROGRESS: at 90.59% examples, 43056 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-02 17:50:57,696 : INFO : EPOCH 5 - PROGRESS: at 91.83% examples, 43029 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:50:58,931 : INFO : EPOCH 5 - PROGRESS: at 93.19% examples, 43047 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:51:00,168 : INFO : EPOCH 5 - PROGRESS: at 94.57% examples, 43065 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:51:01,414 : INFO : EPOCH 5 - PROGRESS: at 95.90% examples, 43075 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:51:02,430 : INFO : EPOCH 5 - PROGRESS: at 97.03% examples, 43117 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-02 17:51:03,549 : INFO : EPOCH 5 - PROGRESS: at 98.23% examples, 43114 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-02 17:51:04,564 : INFO : EPOCH 5 - PROGRESS: at 99.24% examples, 43086 words/s, in_qsize 6, out_qsize 0\n",
      "2018-04-02 17:51:04,821 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-04-02 17:51:04,847 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-02 17:51:04,890 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-02 17:51:05,039 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-02 17:51:05,039 : INFO : EPOCH - 5 : training on 6023662 raw words (4131238 effective words) took 95.7s, 43189 effective words/s\n",
      "2018-04-02 17:51:05,040 : INFO : training on a 30118310 raw words (20655510 effective words) took 488.2s, 42306 effective words/s\n",
      "2018-04-02 17:51:05,041 : INFO : precomputing L2-norms of word weight vectors\n",
      "2018-04-02 17:51:05,137 : INFO : saving Word2Vec object under 300features_40minwords_10context, separately None\n",
      "2018-04-02 17:51:05,138 : INFO : not storing attribute vectors_norm\n",
      "2018-04-02 17:51:05,139 : INFO : not storing attribute cum_table\n",
      "2018-04-02 17:51:05,338 : INFO : saved 300features_40minwords_10context\n"
     ]
    }
   ],
   "source": [
    "# Import the built-in logging module and configure it so that Word2Vec \n",
    "# creates nice output messages\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s',\\\n",
    "    level=logging.INFO)\n",
    "\n",
    "# Set values for various parameters\n",
    "num_features = 300    # Word vector dimensionality                      \n",
    "min_word_count = 40   # Minimum word count                        \n",
    "num_workers = 4       # Number of threads to run in parallel\n",
    "context = 10          # Context window size                                                                                    \n",
    "downsampling = 1e-3   # Downsample setting for frequent words\n",
    "\n",
    "# Initialize and train the model (this will take some time)\n",
    "from gensim.models import word2vec\n",
    "print \"Training model...\"\n",
    "model = word2vec.Word2Vec(sentencesflat, workers=num_workers, \\\n",
    "            size=num_features, min_count = min_word_count, \\\n",
    "            window = context, sample = downsampling)\n",
    "\n",
    "# If you don't plan to train the model any further, calling \n",
    "# init_sims will make the model much more memory-efficient.\n",
    "model.init_sims(replace=True)\n",
    "\n",
    "# It can be helpful to create a meaningful model name and \n",
    "# save the model for later use. You can load it later using Word2Vec.load()\n",
    "model_name = \"300features_40minwords_10context\"\n",
    "model.save(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#model.accuracy('https://raw.githubusercontent.com/RaRe-Technologies/gensim/develop/gensim/test/test_data/questions-words.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# what should we do for whole sentence\n",
    "\n",
    "## 1. Vector Averaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def makeFeatureVec(words, model, num_features):\n",
    "    # Function to average all of the word vectors in a given\n",
    "    # paragraph\n",
    "    #\n",
    "    # Pre-initialize an empty numpy array (for speed)\n",
    "    featureVec = np.zeros((num_features,),dtype=\"float32\")\n",
    "    #\n",
    "    nwords = 0.\n",
    "    # \n",
    "    # Index2word is a list that contains the names of the words in \n",
    "    # the model's vocabulary. Convert it to a set, for speed \n",
    "    index2word_set = set(model.wv.index2word)\n",
    "    #\n",
    "    # Loop over each word in the review and, if it is in the model's\n",
    "    # vocaublary, add its feature vector to the total\n",
    "    for word in words:\n",
    "        if word in index2word_set: \n",
    "            nwords = nwords + 1.\n",
    "            featureVec = np.add(featureVec,model.wv[word])\n",
    "    # \n",
    "    # Divide the result by the number of words to get the average\n",
    "    featureVec = np.divide(featureVec,nwords)\n",
    "    return featureVec\n",
    "\n",
    "\n",
    "def getAvgFeatureVecs(reviews, model, num_features):\n",
    "    # Given a set of reviews (each one a list of words), calculate \n",
    "    # the average feature vector for each one and return a 2D numpy array \n",
    "    # \n",
    "    # Initialize a counter\n",
    "    counter = 0\n",
    "    # \n",
    "    # Preallocate a 2D numpy array, for speed\n",
    "    reviewFeatureVecs = np.zeros((len(reviews),num_features),dtype=\"float32\")\n",
    "    # \n",
    "    # Loop through the reviews\n",
    "    for review in reviews:\n",
    "        # Print a status message every 1000th review\n",
    "        if counter%10000 == 0:\n",
    "            print \"Review %d of %d\" % (counter, len(reviews))\n",
    "        # \n",
    "        # Call the function (defined above) that makes average feature vectors\n",
    "        reviewFeatureVecs[counter] = makeFeatureVec(review, model, \\\n",
    "           num_features)\n",
    "        #\n",
    "        # Increment the counter\n",
    "        counter = counter + 1\n",
    "    return reviewFeatureVecs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "originalreview = pd.read_csv( \"data/labeledTrainData.tsv\", header=0, \n",
    "                             delimiter=\"\\t\", quoting=3 , encoding = 'utf8').review\n",
    "sentences = map(lambda var: word_clean(var, remove_stopwords=True), originalreview)\n",
    "sentences = map(lambda var: var.split(),sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 0 of 25000\n",
      "Review 10000 of 25000\n",
      "Review 20000 of 25000\n"
     ]
    }
   ],
   "source": [
    "X = getAvgFeatureVecs(sentences,model, num_features)\n",
    "\n",
    "X = np.concatenate([X, np.array(traindf[['textblod-polarity','textblod-subjectivity', 'vaderSentiment-compound',\n",
    "            'vaderSentiment-neg','vaderSentiment-neu','vaderSentiment-pos']])],axis = 1)\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.30, random_state=325)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3073  625]\n",
      " [ 554 3248]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.83      0.84      3698\n",
      "          1       0.84      0.85      0.85      3802\n",
      "\n",
      "avg / total       0.84      0.84      0.84      7500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=150)\n",
    "rfc.fit(X_train,y_train)\n",
    "pred = rfc.predict(X_test)\n",
    "\n",
    "print confusion_matrix(y_test,pred)\n",
    "print '\\n'\n",
    "print classification_report(y_test,pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Clustering ¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for K Means clustering:  147.568068027 seconds.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import time\n",
    "\n",
    "start = time.time() # Start time\n",
    "\n",
    "# Set \"k\" (num_clusters) to be 1/5th of the vocabulary size, or an\n",
    "# average of 5 words per cluster\n",
    "word_vectors = model.trainables.syn1neg\n",
    "num_clusters = word_vectors.shape[0] / 5\n",
    "\n",
    "# Initalize a k-means object and use it to extract centroids\n",
    "kmeans_clustering = KMeans( n_clusters = num_clusters )\n",
    "idx = kmeans_clustering.fit_predict( word_vectors )\n",
    "\n",
    "# Get the end time and print how long the process took\n",
    "end = time.time()\n",
    "elapsed = end - start\n",
    "print \"Time taken for K Means clustering: \", elapsed, \"seconds.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cluster 0\n",
      "['chase']\n",
      "\n",
      "Cluster 1\n",
      "['Brendan', 'psychiatrist', 'Dahmer', 'Othello', 'maker', 'adaption', 'Gerard', 'painter', 'editor', 'penned', 'playwright', 'biography', 'journalist', 'novelist', 'Antwone', 'Von', 'Blaise', 'author', 'Luzhin']\n",
      "\n",
      "Cluster 2\n",
      "['cream', 'incest', 'r', 'grand', 'smoking', 'cup', 'pot', 'tea']\n",
      "\n",
      "Cluster 3\n",
      "['bank', 'dogs', 'gambling', 'spree', 'Marty', 'cattle', 'rob', 'tribe', 'rid', 'collect']\n"
     ]
    }
   ],
   "source": [
    "# Create a Word / Index dictionary, mapping each vocabulary word to\n",
    "# a cluster number                                                                                            \n",
    "word_centroid_map = dict(zip( model.wv.index2word, idx ))\n",
    "\n",
    "# For the first 10 clusters\n",
    "for cluster in xrange(0,4):\n",
    "    #\n",
    "    # Print the cluster number  \n",
    "    print \"\\nCluster %d\" % cluster\n",
    "    #\n",
    "    # Find all of the words for that cluster number, and print them out\n",
    "    words = []\n",
    "    for i in xrange(0,len(word_centroid_map.values())):\n",
    "        if( word_centroid_map.values()[i] == cluster ):\n",
    "            words.append(word_centroid_map.keys()[i])\n",
    "    print words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_bag_of_centroids( wordlist, word_centroid_map ):\n",
    "    #\n",
    "    # The number of clusters is equal to the highest cluster index\n",
    "    # in the word / centroid map\n",
    "    num_centroids = max( word_centroid_map.values() ) + 1\n",
    "    #\n",
    "    # Pre-allocate the bag of centroids vector (for speed)\n",
    "    bag_of_centroids = np.zeros( num_centroids, dtype=\"float32\" )\n",
    "    #\n",
    "    # Loop over the words in the review. If the word is in the vocabulary,\n",
    "    # find which cluster it belongs to, and increment that cluster count \n",
    "    # by one\n",
    "    for word in wordlist:\n",
    "        if word in word_centroid_map:\n",
    "            index = word_centroid_map[word]\n",
    "            bag_of_centroids[index] += 1\n",
    "    #\n",
    "    # Return the \"bag of centroids\"\n",
    "    return bag_of_centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Pre-allocate an array for the training set bags of centroids (for speed)\n",
    "train_centroids = np.zeros( (len(sentences), num_clusters), \\\n",
    "    dtype=\"float32\" )\n",
    "\n",
    "# Transform the training set reviews into bags of centroids\n",
    "counter = 0\n",
    "for review in sentences:\n",
    "    train_centroids[counter] = create_bag_of_centroids( review, \\\n",
    "        word_centroid_map )\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3121  577]\n",
      " [ 616 3186]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.84      0.84      3698\n",
      "          1       0.85      0.84      0.84      3802\n",
      "\n",
      "avg / total       0.84      0.84      0.84      7500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = np.concatenate([train_centroids, np.array(traindf[['textblod-polarity','textblod-subjectivity', 'vaderSentiment-compound',\n",
    "            'vaderSentiment-neg','vaderSentiment-neu','vaderSentiment-pos']])],axis = 1)\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.30, random_state=325)\n",
    "rfc = RandomForestClassifier(n_estimators=150)\n",
    "rfc.fit(X_train,y_train)\n",
    "pred = rfc.predict(X_test)\n",
    "\n",
    "print confusion_matrix(y_test,pred)\n",
    "print '\\n'\n",
    "print classification_report(y_test,pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def text_preprocess(sentence):\n",
    "    # 1. Remove HTML\n",
    "    review_text = BeautifulSoup(sentence).get_text() \n",
    "    # 2. Remove non-letters        \n",
    "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", review_text) \n",
    "    # 3. Convert to lower case, split into individual words\n",
    "    words = letters_only.lower().split()                             \n",
    "    # 4. Remove stop words\n",
    "    stops = set(stopwords.words(\"english\"))                   \n",
    "    meaningful_words = [w for w in words if not w in stops]   \n",
    "\n",
    "    return meaningful_words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "pipeline1 = Pipeline([\n",
    "    ('bow', CountVectorizer(analyzer=text_preprocess)),  # strings to token integer counts\n",
    "    ('tfidf', TfidfTransformer()),  # integer counts to weighted TF-IDF scores\n",
    "    ('classifier', MultinomialNB()),  # train on TF-IDF vectors w/ Naive Bayes classifier\n",
    "])\n",
    "\n",
    "pipeline2 = Pipeline([\n",
    "    ('bow', CountVectorizer(analyzer=text_preprocess)),  # strings to token integer counts\n",
    "    ('tfidf', TfidfTransformer()),  # integer counts to weighted TF-IDF scores\n",
    "    ('classifier', RandomForestClassifier(n_estimators=150)),  # train on TF-IDF vectors w/ Naive Bayes classifier\n",
    "])\n",
    "\n",
    "pipeline3 = Pipeline([\n",
    "    ('bow', CountVectorizer(min_df=3,  max_features=None, \n",
    "        strip_accents='unicode', analyzer=text_preprocess,token_pattern=r'\\w{1,}',\n",
    "        ngram_range=(1, 2),  stop_words = 'english')),  # strings to token integer counts\n",
    "    ('tfidf', TfidfTransformer()),  # integer counts to weighted TF-IDF scores\n",
    "    ('classifier', LogisticRegression(penalty='l2', dual=True, tol=0.0001, \n",
    "                         C=1, fit_intercept=True, intercept_scaling=1.0, \n",
    "                         class_weight=None, random_state=None)),  # train on TF-IDF vectors w/ Naive Bayes classifier\n",
    "])\n",
    "\n",
    "\n",
    "pipeline4 = Pipeline([('vec', CountVectorizer(\n",
    "    binary=False,\n",
    "    tokenizer=lambda text: text.split(),\n",
    "    max_df=0.5,\n",
    "    max_features=None,\n",
    "    stop_words=None,\n",
    "    ngram_range=(1,2))),\n",
    "('tfidf', TfidfTransformer(\n",
    "    norm='l2',\n",
    "    use_idf=True,\n",
    "    sublinear_tf=False)),\n",
    "('clf', MultinomialNB(alpha=0.1))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3209  558]\n",
      " [ 539 3194]]\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.85      0.85      3767\n",
      "          1       0.85      0.86      0.85      3733\n",
      "\n",
      "avg / total       0.85      0.85      0.85      7500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "msg_train, msg_test, label_train, label_test = train_test_split(traindf.review, traindf.sentiment, \n",
    "                                                                test_size=0.3, random_state=325)\n",
    "\n",
    "pipeline2.fit(msg_train,label_train)\n",
    "predictions2 = pipeline2.predict(msg_test)\n",
    "print confusion_matrix(label_test,predictions2)\n",
    "print \n",
    "print classification_report(label_test,predictions2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3286  481]\n",
      " [ 541 3192]]\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.87      0.87      3767\n",
      "          1       0.87      0.86      0.86      3733\n",
      "\n",
      "avg / total       0.86      0.86      0.86      7500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipeline1.fit(msg_train,label_train)\n",
    "predictions1 = pipeline1.predict(msg_test)\n",
    "print confusion_matrix(label_test,predictions1)\n",
    "print \n",
    "print classification_report(label_test,predictions1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3299  468]\n",
      " [ 346 3387]]\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.88      0.89      3767\n",
      "          1       0.88      0.91      0.89      3733\n",
      "\n",
      "avg / total       0.89      0.89      0.89      7500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipeline3.fit(msg_train,label_train)\n",
    "predictions3 = pipeline3.predict(msg_test)\n",
    "print confusion_matrix(label_test,predictions3)\n",
    "print \n",
    "print classification_report(label_test,predictions3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3310  457]\n",
      " [ 401 3332]]\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.88      0.89      3767\n",
      "          1       0.88      0.89      0.89      3733\n",
      "\n",
      "avg / total       0.89      0.89      0.89      7500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipeline4.fit(msg_train,label_train)\n",
    "predictions4 = pipeline4.predict(msg_test)\n",
    "print confusion_matrix(label_test,predictions4)\n",
    "print \n",
    "print classification_report(label_test,predictions4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "class ItemSelector(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"For data grouped by feature, select subset of data at a provided key.\n",
    "\n",
    "    The data is expected to be stored in a 2D data structure, where the first\n",
    "    index is over features and the second is over samples.  i.e.\n",
    "\n",
    "    >> len(data[key]) == n_samples\n",
    "\n",
    "    Please note that this is the opposite convention to scikit-learn feature\n",
    "    matrixes (where the first index corresponds to sample).\n",
    "\n",
    "    ItemSelector only requires that the collection implement getitem\n",
    "    (data[key]).  Examples include: a dict of lists, 2D numpy array, Pandas\n",
    "    DataFrame, numpy record array, etc.\n",
    "\n",
    "    >> data = {'a': [1, 5, 2, 5, 2, 8],\n",
    "               'b': [9, 4, 1, 4, 1, 3]}\n",
    "    >> ds = ItemSelector(key='a')\n",
    "    >> data['a'] == ds.transform(data)\n",
    "\n",
    "    ItemSelector is not designed to handle data grouped by sample.  (e.g. a\n",
    "    list of dicts).  If your data is structured this way, consider a\n",
    "    transformer along the lines of `sklearn.feature_extraction.DictVectorizer`.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    key : hashable, required\n",
    "        The key corresponding to the desired value in a mappable.\n",
    "    \"\"\"\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, data_dict):\n",
    "        return data_dict[self.key]\n",
    "\n",
    "pipeline5 = Pipeline([\n",
    "        ('union', FeatureUnion(\n",
    "            transformer_list=[\n",
    "            ('tfidf_out', Pipeline([\n",
    "                ('selector', ItemSelector(key='review')),\n",
    "                ('bow', CountVectorizer(min_df=3,  max_features=None, \n",
    "                            strip_accents='unicode', analyzer=text_preprocess,token_pattern=r'\\w{1,}',\n",
    "                            ngram_range=(1, 2),  stop_words = 'english')),  # strings to token integer counts\n",
    "                ('tfidf', TfidfTransformer())])),\n",
    "            ('body_bow', Pipeline([\n",
    "                ('selector', ItemSelector(key=['textblod-polarity','textblod-subjectivity', 'vaderSentiment-compound',\n",
    "            'vaderSentiment-neg','vaderSentiment-neu','vaderSentiment-pos']))]))],\n",
    "        )),\n",
    "        ('classifier', LogisticRegression(penalty='l2', dual=True, tol=0.0001, \n",
    "                         C=1, fit_intercept=True, intercept_scaling=1.0, \n",
    "                         class_weight=None, random_state=None))  ])\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3244  454]\n",
      " [ 434 3368]]\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.88      0.88      3698\n",
      "          1       0.88      0.89      0.88      3802\n",
      "\n",
      "avg / total       0.88      0.88      0.88      7500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "msg_train, msg_test, label_train, label_test = train_test_split(traindf, traindf.sentiment, \n",
    "                                                                test_size=0.3, random_state=325)\n",
    "\n",
    "pipeline5.fit(msg_train,label_train)\n",
    "predictions5 = pipeline5.predict(msg_test)\n",
    "print confusion_matrix(label_test,predictions5)\n",
    "print \n",
    "print classification_report(label_test,predictions5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### // Adding sentiment as features slightly decrease the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning and parsing movie reviews...\n",
      "\n",
      "vectorizing...  fitting pipeline...  20 Fold CV Score:  0.958320512\n",
      "Retrain on all training data, predicting test labels...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##### sweezyjeezy solution\n",
    "def review_to_wordlist( review, remove_stopwords=False ):\n",
    "    # Function to convert a document to a sequence of words,\n",
    "    # optionally removing stop words.  Returns a list of words.\n",
    "    #\n",
    "    # 1. Remove HTML\n",
    "    review_text = BeautifulSoup(review).get_text()\n",
    "    #\n",
    "    # 2. Remove non-letters\n",
    "    review_text = re.sub(\"[^a-zA-Z]\",\" \", review_text)\n",
    "    #\n",
    "    # 3. Convert words to lower case and split them\n",
    "    words = review_text.lower().split()\n",
    "    #\n",
    "    # 4. Optionally remove stop words (false by default)\n",
    "    if remove_stopwords:\n",
    "        stops = set(stopwords.words(\"english\"))\n",
    "        words = [w for w in words if not w in stops]\n",
    "    #\n",
    "    # 5. Return a list of words\n",
    "    return(words)\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import cross_validation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "train = pd.read_csv('data/labeledTrainData.tsv', header=0, \\\n",
    "                delimiter=\"\\t\", quoting=3)\n",
    "test = pd.read_csv('data/testData.tsv', header=0, delimiter=\"\\t\", \\\n",
    "               quoting=3 )\n",
    "y = train[\"sentiment\"]  \n",
    "print \"Cleaning and parsing movie reviews...\\n\"      \n",
    "traindata = []\n",
    "for i in xrange( 0, len(train[\"review\"])):\n",
    "    traindata.append(\" \".join(review_to_wordlist(train[\"review\"][i], False)))\n",
    "testdata = []\n",
    "for i in xrange(0,len(test[\"review\"])):\n",
    "    testdata.append(\" \".join(review_to_wordlist(test[\"review\"][i], False)))\n",
    "print 'vectorizing... ', \n",
    "tfv = TfidfVectorizer(min_df=3,  max_features=None, \n",
    "        strip_accents='unicode', analyzer='word',token_pattern=r'\\w{1,}',\n",
    "        ngram_range=(1, 2), use_idf=1,smooth_idf=1,sublinear_tf=1,\n",
    "        stop_words = 'english')\n",
    "X_all = traindata + testdata\n",
    "lentrain = len(traindata)\n",
    "\n",
    "print \"fitting pipeline... \",\n",
    "tfv.fit(X_all)\n",
    "X_all = tfv.transform(X_all)\n",
    "\n",
    "X = X_all[:lentrain]\n",
    "X_test = X_all[lentrain:]\n",
    "\n",
    "model = LogisticRegression(penalty='l2', dual=True, tol=0.0001, \n",
    "                         C=1, fit_intercept=True, intercept_scaling=1.0, \n",
    "                         class_weight=None, random_state=None)\n",
    "print \"20 Fold CV Score: \", np.mean(cross_validation.cross_val_score(model, X, y, cv=20, scoring='roc_auc'))\n",
    "\n",
    "print \"Retrain on all training data, predicting test labels...\\n\"\n",
    "model.fit(X,y)\n",
    "result = model.predict_proba(X_test)[:,1]\n",
    "output = pd.DataFrame( data={\"id\":test[\"id\"], \"sentiment\":result} )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
